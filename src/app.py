import streamlit as st
import os
import sys
from langchain_openai import ChatOpenAI
from langchain_chroma import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from dotenv import load_dotenv

# --- AYARLAR ---
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

try:
    from src.config import CHROMA_DB_DIR, EMBEDDING_MODEL_NAME
except ImportError:
    CHROMA_DB_DIR = os.path.join(parent_dir, 'data', 'chroma_db')
    EMBEDDING_MODEL_NAME = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"

load_dotenv()
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
MODEL_NAME = "deepseek-chat"
BASE_URL = "https://api.deepseek.com"

# --- KAYNAKLAR ---
if not DEEPSEEK_API_KEY and __name__ == "__main__":
    st.error("API Key Eksik!")

embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME)
vector_db = Chroma(persist_directory=CHROMA_DB_DIR, embedding_function=embeddings)
llm = ChatOpenAI(
    model=MODEL_NAME, 
    api_key=DEEPSEEK_API_KEY, 
    base_url=BASE_URL, 
    temperature=0.1 
)

# ---------------------------------------------------------
# â­ FINAL TURBO BEYÄ°N (V5 - BIG CONTEXT) â­
# ---------------------------------------------------------
def get_response_from_deepseek(question):
    """
    RAG Stratejisi:
    - KÃ¼Ã§Ã¼k parÃ§alar (512 char) kullanÄ±yoruz ama SAYIYI ARTIRIYORUZ.
    - k=25: YaklaÅŸÄ±k 3-4 sayfalÄ±k yoÄŸun bilgi verir.
    - lambda_mult=0.5: Ã‡eÅŸitliliÄŸi artÄ±rÄ±r, sadece benzerleri deÄŸil, 
      farklÄ± yerlerdeki bilgileri de toplar.
    """
    # 1. MMR ARAMA (GeniÅŸletilmiÅŸ)
    docs = vector_db.max_marginal_relevance_search(
        question, 
        k=25,           # ARTTIRILDI: Modele daha fazla kanÄ±t sunuyoruz.
        fetch_k=60,     # ARTTIRILDI: Daha geniÅŸ havuzdan seÃ§iyor.
        lambda_mult=0.5 # DENGELENDÄ°: Hem benzerlik hem Ã§eÅŸitlilik (0.5 ideal).
    )
    
    chunk_texts = [d.page_content for d in docs]
    context_text = "\n---\n".join(chunk_texts)
    
    # 2. PROMPT (Analitik ve Esnek)
    system_prompt = ChatPromptTemplate.from_template("""
    Sen Ã‡ukurova Ãœniversitesi mevzuatlarÄ±nda uzman, son derece dikkatli bir akademik asistansÄ±n.
    AÅŸaÄŸÄ±daki MEVZUAT PARÃ‡ALARINI (CONTEXT) incele ve soruya cevap ver.

    CONTEXT (KANITLAR):
    {context}
    
    SORU: {question}

    ANALÄ°Z ADIMLARI:
    1. Sorudaki anahtar kelimelerin (Ã¶rn: "GNO", "Mezuniyet", "Yaz okulu") eÅŸ anlamlÄ±larÄ±nÄ± metinde ara.
    2. CevabÄ± parÃ§alarÄ± birleÅŸtirerek oluÅŸtur. Tek bir maddede bulamayabilirsin.
    3. SayÄ±sal verileri (gÃ¼n, yÃ¼zde, not) kesinlikle metinden doÄŸrula.
    4. EÄŸer metinde "AÃ§Ä±lmaz" yazÄ±yorsa bunu "Yoktur" olarak yorumla (MantÄ±ksal Ã‡Ä±karÄ±m).
    5. CevabÄ± kÄ±sa ve net ver.
    6. Bilgi kesinlikle yoksa "YÃ¶netmeliklerde bu bilgi bulunmamaktadÄ±r" de.
    
    CEVAP:
    """)
    
    chain = system_prompt | llm
    response = chain.invoke({"context": context_text, "question": question})
    
    return response.content

# ---------------------------------------------------------
# STREAMLIT ARAYÃœZÃœ
# ---------------------------------------------------------
if __name__ == "__main__":
    st.set_page_config(page_title="Ã‡Ãœ Asistan", page_icon="ğŸ“", layout="wide")
    st.title("ğŸ“ Ã‡ukurova Mevzuat AsistanÄ± (Turbo Mode)")
    
    with st.sidebar:
        st.success("Mod: Turbo (512 Chunk x 25)")
        st.info("Kapasite: YÃ¼ksek BaÄŸlam")
        if st.button("SÄ±fÄ±rla"):
            st.session_state.messages = []
            st.rerun()

    if "messages" not in st.session_state:
        st.session_state.messages = [{"role": "assistant", "content": "SorularÄ± bekliyorum Kingo! ğŸ‘‘"}]

    for msg in st.session_state.messages:
        st.chat_message(msg["role"]).write(msg["content"])

    if prompt := st.chat_input():
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.chat_message("user").write(prompt)

        with st.chat_message("assistant"):
            with st.status("ğŸ§  GeniÅŸ kapsamlÄ± tarama yapÄ±lÄ±yor..."):
                resp = get_response_from_deepseek(prompt)
            st.write(resp)
            st.session_state.messages.append({"role": "assistant", "content": resp})
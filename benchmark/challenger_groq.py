import os
import json
import pandas as pd
import sys
from groq import Groq
from openai import OpenAI
from dotenv import load_dotenv

# --- AYARLAR VE GÃœVENLÄ°K ---
# .env dosyasÄ±ndaki deÄŸiÅŸkenleri yÃ¼kle
load_dotenv()

# API AnahtarlarÄ±nÄ± Ã‡evresel DeÄŸiÅŸkenlerden Al
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")

# Yol ayarlarÄ±
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

# --- Ä°STEMCÄ° KURULUMU VE KONTROLÃœ ---
if not GROQ_API_KEY:
    print("âŒ HATA: GROQ_API_KEY bulunamadÄ±! LÃ¼tfen .env dosyanÄ±zÄ± kontrol edin.")
    sys.exit(1)

if not DEEPSEEK_API_KEY:
    print("âŒ HATA: DEEPSEEK_API_KEY bulunamadÄ±! LÃ¼tfen .env dosyanÄ±zÄ± kontrol edin.")
    sys.exit(1)

try:
    client_groq = Groq(api_key=GROQ_API_KEY)
    client_judge = OpenAI(api_key=DEEPSEEK_API_KEY, base_url="https://api.deepseek.com")
except Exception as e:
    print(f"âŒ Ä°stemci hatasÄ±: {e}")
    sys.exit(1)

def get_challenger_response(question):
    """
    RAGSIZ Rakip (Llama 3.3 - En GÃ¼ncel SÃ¼rÃ¼m).
    YÃ¶netmelik eriÅŸimi olmadan sadece modelin kendi bilgisiyle cevap Ã¼retir.
    """
    prompt = f"""
    Sen bir Ã¼niversite Ã¶ÄŸrencisisin. AÅŸaÄŸÄ±daki soruyu Ã‡ukurova Ãœniversitesi yÃ¶netmeliÄŸine gÃ¶re cevapla.
    Elinin altÄ±nda yÃ¶netmelik metni YOK. Sadece hafÄ±zandaki bilgileri kullan.
    EÄŸer spesifik kuralÄ± bilmiyorsan, genel bir tahmin yÃ¼rÃ¼t.
    
    SORU: {question}
    CEVAP:
    """
    try:
        chat_completion = client_groq.chat.completions.create(
            model="llama-3.3-70b-versatile", 
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5,
        )
        return chat_completion.choices[0].message.content
    except Exception as e:
        return f"HATA: {str(e)}"

def evaluate_with_judge(question, ground_truth, model_answer):
    """
    HAKEM DEÄERLENDÄ°RMESÄ° (DeepSeek)
    CevabÄ± referans cevaba gÃ¶re 0-5 arasÄ±nda puanlar.
    """
    judge_prompt = f"""
    Sen akademik bir hakemsin. AÅŸaÄŸÄ±daki cevabÄ± referans cevaba gÃ¶re 0-5 arasÄ± puanla.
    
    SORU: {question}
    REFERANS CEVAP: {ground_truth}
    ADAY CEVAP: {model_answer}
    
    DEÄERLENDÄ°RME KRÄ°TERLERÄ°:
    1. DoÄŸru bilgi (+1)
    2. SayÄ±sal doÄŸruluk (+1)
    3. Kapsam (+1)
    4. MantÄ±k (+1)
    5. HalÃ¼sinasyon Yok (+1)
    
    Ã–NEMLÄ°: Ã‡ukurova Ãœniversitesi'ne Ã¶zel kurallarÄ± (sayÄ±, gÃ¼n, madde) iÃ§ermeyen genel cevaplara DÃœÅÃœK PUAN VER.
    
    Ã‡Ä±ktÄ± FormatÄ± (JSON):
    {{
        "Puan": (0-5 arasÄ± sayÄ±),
        "Durum": "BAÅARILI" veya "BAÅARISIZ",
        "GerekÃ§e": "KÄ±sa aÃ§Ä±klama"
    }}
    """
    try:
        response = client_judge.chat.completions.create(
            model="deepseek-chat",
            messages=[{"role": "user", "content": judge_prompt}],
            temperature=0
        )
        content = response.choices[0].message.content.replace("```json", "").replace("```", "").strip()
        return json.loads(content)
    except:
        return {"Puan": 0, "Durum": "HATA", "GerekÃ§e": "Hakem hatasÄ±"}

def main():
    print("ğŸ¥Š RAKÄ°P TESTÄ° BAÅLIYOR: DeepSeek RAG vs. Llama 3.3 (No-RAG)")
    print("------------------------------------------------------------")
    
    data_path = os.path.join(current_dir, "benchmark_data.json")
    
    # Veri seti kontrolÃ¼
    if not os.path.exists(data_path):
        print(f"âŒ HATA: Veri dosyasÄ± bulunamadÄ±: {data_path}")
        return

    try:
        with open(data_path, "r", encoding="utf-8") as f:
            data = json.load(f)
    except Exception as e:
        print(f"âŒ Veri okuma hatasÄ±: {e}")
        return

    results = []
    total_score = 0
    
    for index, item in enumerate(data):
        question = item["question"]
        ground_truth = item["ground_truth"]
        
        print(f"[{index+1}/{len(data)}] Llama-3.3 CevaplÄ±yor: {question[:30]}...")
        
        # 1. Rakip CevaplasÄ±n
        challenger_response = get_challenger_response(question)
        
        # 2. Hakem PuanlasÄ±n
        eval_result = evaluate_with_judge(question, ground_truth, challenger_response)
        score = eval_result.get("Puan", 0)
        total_score += score
        
        results.append({
            "ID": item["id"],
            "Soru": question,
            "Referans Cevap": ground_truth,
            "Rakip CevabÄ± (No-RAG)": challenger_response,
            "Puan": score,
            "Durum": eval_result.get("Durum"),
            "GerekÃ§e": eval_result.get("GerekÃ§e")
        })

    # KarÅŸÄ±laÅŸtÄ±rma Raporu (Opsiyonel: EÄŸer Ã¶nceki sonuÃ§ dosyasÄ± varsa ortalamayÄ± Ã§eker)
    our_avg = 4.00 # VarsayÄ±lan deÄŸer
    our_results_path = os.path.join(current_dir, "deepseek_final_sonuc_v3.xlsx")
    
    if os.path.exists(our_results_path):
        try:
            df_ours = pd.read_excel(our_results_path)
            our_avg = df_ours["Puan (0-5)"].mean()
        except:
            pass
        
    challenger_avg = total_score / len(results) if results else 0
    
    print("\n" + "="*50)
    print(f"ğŸ FÄ°NAL KARÅILAÅTIRMA SONUCU")
    print(f"ğŸ¦ BÄ°ZÄ°M SÄ°STEM (RAG): {our_avg:.2f} / 5.00")
    print(f"ğŸ± RAKÄ°P (Llama 3.3):  {challenger_avg:.2f} / 5.00")
    print("="*50)
    
    output_file = os.path.join(current_dir, "challenger_groq_results_v2.xlsx")
    pd.DataFrame(results).to_excel(output_file, index=False)
    print(f"SonuÃ§lar kaydedildi: {output_file}")

if __name__ == "__main__":
    main()
import json
import pandas as pd
import time
import os
import sys
from openai import OpenAI
from dotenv import load_dotenv

# --- YOL AYARI (PATH FIX) ---
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

# ModÃ¼l import kontrolÃ¼
try:
    from src.app import get_response_from_deepseek
    print("âœ… BAÅARILI: src.app dosyasÄ±na eriÅŸildi.")
except ImportError as e:
    print("\nğŸš¨ KRÄ°TÄ°K HATA: src.app dosyasÄ± bulunamadÄ±!")
    print(f"Hata DetayÄ±: {e}")
    sys.exit(1)

load_dotenv()

# DeepSeek Hakem YapÄ±landÄ±rmasÄ±
client = OpenAI(
    api_key=os.getenv("DEEPSEEK_API_KEY"),
    base_url="https://api.deepseek.com"
)

def evaluate_with_judge(question, ground_truth, model_answer):
    """
    Hakem Yapay Zeka cevabÄ± 5 kriter Ã¼zerinden deÄŸerlendirir.
    Her baÅŸarÄ±lÄ± kriter 1 puandÄ±r. Toplam 5 Ã¼zerinden puanlanÄ±r.
    """
    judge_prompt = f"""
    Sen akademik bir deÄŸerlendirme uzmanÄ±sÄ±n. AÅŸaÄŸÄ±daki Ã¶ÄŸrenci sorusuna verilen Yapay Zeka cevabÄ±nÄ±, 
    Referans Cevap (Ground Truth) ile karÅŸÄ±laÅŸtÄ±rarak deÄŸerlendireceksin.
    
    SORU: {question}
    REFERANS CEVAP: {ground_truth}
    YZ CEVABI: {model_answer}
    
    LÃ¼tfen cevabÄ± ÅŸu 5 kriter Ã¼zerinden analiz et. Her kriter 1 puandÄ±r:
    1. EriÅŸim (Retrieval): DoÄŸru bilgi bulunmuÅŸ mu? (+1 Puan)
    2. DoÄŸruluk (Precision): SayÄ±sal veriler ve tarihler doÄŸru mu? (+1 Puan)
    3. Kapsam (Completeness): Cevap eksiksiz mi? (+1 Puan)
    4. MantÄ±k (Reasoning): KoÅŸullu durumlar doÄŸru yorumlanmÄ±ÅŸ mÄ±? (+1 Puan)
    5. DÃ¼rÃ¼stlÃ¼k (Honesty): HalÃ¼sinasyon (uydurma) yok mu? (+1 Puan)
    
    DEÄERLENDÄ°RME KURALI:
    - Toplam puan 0 ile 5 arasÄ±nda bir tam sayÄ± olmalÄ±dÄ±r.
    - 3 ve Ã¼zeri puanlar "BAÅARILI", 3'Ã¼n altÄ± "BAÅARISIZ" sayÄ±lÄ±r.
    
    Ã‡Ä±ktÄ± FormatÄ± (Sadece bu JSON formatÄ±nÄ± dÃ¶ndÃ¼r):
    {{
        "Puan": (0-5 arasÄ± tam sayÄ±),
        "GerekÃ§e": "KÄ±sa bir deÄŸerlendirme cÃ¼mlesi",
        "Durum": "BAÅARILI" veya "BAÅARISIZ"
    }}
    """
    
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "Sen adil bir hakemsin. Sadece JSON dÃ¶ndÃ¼r."},
                {"role": "user", "content": judge_prompt}
            ],
            temperature=0
        )
        content = response.choices[0].message.content.replace("```json", "").replace("```", "").strip()
        return json.loads(content)
    except Exception as e:
        print(f"Hakem HatasÄ±: {e}")
        return {"Puan": 0, "GerekÃ§e": "Hata oluÅŸtu", "Durum": "HATA"}

def main():
    print("ğŸš€ Benchmark Testi BaÅŸlatÄ±lÄ±yor... (5'lik Sistem)")
    
    # Veri Setini YÃ¼kle
    data_path = os.path.join(current_dir, "benchmark_data.json")
    try:
        with open(data_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        print(f"ğŸ“‚ {len(data)} adet soru yÃ¼klendi.")
    except FileNotFoundError:
        print("âŒ HATA: 'benchmark_data.json' bulunamadÄ±!")
        return

    results = []
    total_score = 0
    passed_count = 0
    
    for index, item in enumerate(data):
        q_id = item.get("id", index+1)
        question = item["question"]
        ground_truth = item["ground_truth"]
        
        print(f"\n[{index+1}/{len(data)}] Soru Ä°ÅŸleniyor: {question[:40]}...")
        
        try:
            start_time = time.time()
            model_response = get_response_from_deepseek(question) 
            duration = time.time() - start_time
        except Exception as e:
            model_response = f"HATA: {str(e)}"
            duration = 0

        eval_result = evaluate_with_judge(question, ground_truth, model_response)
        
        score = eval_result.get("Puan", 0)
        total_score += score
        status = eval_result.get("Durum", "BELÄ°RSÄ°Z")
        
        # Kod tarafÄ±nda da garanti kontrol (3 altÄ± kalÄ±r)
        if score < 3:
            status = "BAÅARISIZ âŒ"
        else:
            status = "BAÅARILI âœ…"
            passed_count += 1
            
        results.append({
            "ID": q_id,
            "Soru": question,
            "Referans Cevap": ground_truth,
            "Model CevabÄ±": model_response,
            "Puan (0-5)": score,
            "Durum": status,
            "GerekÃ§e": eval_result.get("GerekÃ§e", ""),
            "SÃ¼re (sn)": round(duration, 2)
        })

    if len(results) > 0:
        avg_score = total_score / len(results)
        success_rate = (passed_count / len(results)) * 100
        
        df = pd.DataFrame(results)
        output_file = os.path.join(current_dir, "deepseek_final_sonuc_v3.xlsx")
        df.to_excel(output_file, index=False)
        
        print("\n" + "="*50)
        print(f"ğŸ‰ TEST TAMAMLANDI! (5 Ãœzerinden)")
        print(f"ğŸ“Š Ortalama Puan: {avg_score:.2f} / 5.00")
        print(f"ğŸ“ˆ BaÅŸarÄ± OranÄ±: %{success_rate:.1f} (GeÃ§en Soru SayÄ±sÄ±: {passed_count}/{len(results)})")
        print(f"ğŸ“„ Rapor Kaydedildi: {output_file}")
        print("="*50)
        
        if avg_score >= 4.5:
            print("ğŸ† MÃœKEMMEL! We killed it! ğŸ”¥")
        elif avg_score >= 3.5:
            print("âœ… GAYET Ä°YÄ°. Hoca beÄŸenir.")
        else:
            print("âš ï¸ KRÄ°TÄ°K. OrtalamayÄ± yÃ¼kseltmemiz lazÄ±m.")

if __name__ == "__main__":
    main()